{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5IVXtR5FdWRgvbg//ovk6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hang-1n-there/Resnet_CIFA10/blob/main/resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbvEEdZSzfZ0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  mul = 1 # 출력 채널 수를 조절\n",
        "\n",
        "  def __init__(self, in_channel, out_channel, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "\n",
        "    if stride !=1:\n",
        "      self.shortcut = nn.Sequential(\n",
        "        nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(out_channel),\n",
        "      )\n",
        "\n",
        "  def forward(self,x):\n",
        "    result = self.conv1(x)\n",
        "    result = self.bn1(result)\n",
        "    result = F.relu(result)\n",
        "    result = self.conv2(x)\n",
        "    result = self.bn2(result)\n",
        "    result += self.shortcut(x)\n",
        "    result = F.relu(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "class BottleNeck(nn.Module):\n",
        "    mul = 4\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, stride=1):\n",
        "        super(BottleNeck, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(out_channel, out_channel * self.mul, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channel * self.mul)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channel != out_channel * self.mul:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channel, out_channel * self.mul, kernel_size=1, stride=stride, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(out_channel * self.mul)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        result = F.relu(self.bn1(self.conv1(x)))\n",
        "        result = F.relu(self.bn2(self.conv2(result)))\n",
        "        result = self.bn3(self.conv3(result))\n",
        "\n",
        "        shortcut = self.shortcut(x)\n",
        "        result += shortcut\n",
        "        result = F.relu(result)\n",
        "\n",
        "        return result\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "  def __init__(self, block, num_blocks, num_classes = 10):\n",
        "    super(Resnet, self).__init__()\n",
        "\n",
        "    self.in_channel = 64\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2, padding=3)\n",
        "    self.bn1 = nn.BatchNorm2d(self.in_channel)\n",
        "    self.maxpool1 = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "\n",
        "    self.layer1 = self.make_layer(block, 64, num_blocks[0], stride=1)\n",
        "    self.layer2 = self.make_layer(block, 128, num_blocks[0], stride=1)\n",
        "    self.layer3 = self.make_layer(block, 256, num_blocks[0], stride=1)\n",
        "    self.layer4 = self.make_layer(block, 518, num_blocks[0], stride=1)\n",
        "    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.linear = nn.Linear(2072, num_classes)\n",
        "\n",
        "  def make_layer(self, block, out_channel, num_blocks, stride):\n",
        "    # 다운샘플링을 위해 첫 번째 블럭에만 stride 적용\n",
        "    strides = [stride] + [1] * (num_blocks - 1)\n",
        "    layers = []\n",
        "\n",
        "    for num_block in range(num_blocks):\n",
        "      layers.append(block(self.in_channel, out_channel, strides[num_block]))\n",
        "      self.in_channel = block.mul * out_channel\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    result = self.conv1(x)\n",
        "    result = self.bn1(result)\n",
        "    result = F.relu(result)\n",
        "    result = self.maxpool1(result)\n",
        "    result = self.layer1(result)\n",
        "    result = self.layer2(result)\n",
        "    result = self.layer3(result)\n",
        "    result = self.layer4(result)\n",
        "    result = self.avgpool(result)\n",
        "    result = torch.flatten(result, 1)\n",
        "    result = self.linear(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "def ResNet18():\n",
        "    return Resnet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "def ResNet34():\n",
        "    return Resnet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "def ResNet50():\n",
        "    return Resnet(BottleNeck, [3, 4, 6, 3])\n",
        "\n",
        "def ResNet101():\n",
        "    return Resnet(BottleNeck, [3, 4, 23, 3])\n",
        "\n",
        "def ResNet152():\n",
        "    return Resnet(BottleNeck, [3, 8, 36, 3])"
      ],
      "metadata": {
        "id": "9hgOUDN27I0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "MPlhRFMsZBTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Learning Rate Scheduler\n",
        "def lr_scheduler(optimizer, epoch):\n",
        "    lr = learning_rate\n",
        "    if epoch >= 50:\n",
        "        lr /= 10\n",
        "    if epoch >= 100:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "# Xavier\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "metadata": {
        "id": "rnN9jdE2Zy4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=8)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIRO0AHzo7ms",
        "outputId": "3ff42593-6986-46ce-e6ec-ec597ea2a9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 40829185.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "model = ResNet50()"
      ],
      "metadata": {
        "id": "w-fVqSwyo9WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.apply(init_weights)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O094atDxo_Kt",
        "outputId": "aaeec407-5031-4982-8e8b-9a51faebd2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-cb3abaf3ef20>:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  torch.nn.init.xavier_uniform(m.weight)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "num_epoch = 150\n",
        "model_name = 'model.pth'\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "train_loss = 0\n",
        "valid_loss = 0\n",
        "correct = 0\n",
        "total_cnt = 0\n",
        "best_acc = 0"
      ],
      "metadata": {
        "id": "zm-1LTsKpAui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in tqdm(range(num_epoch)):\n",
        "    print(f\"====== { epoch+1} epoch of { num_epoch } ======\")\n",
        "    model.train()\n",
        "    lr_scheduler(optimizer, epoch)\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "    correct = 0\n",
        "    total_cnt = 0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        #  input and target\n",
        "        batch[0], batch[1] = batch[0].to(device), batch[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(batch[0])\n",
        "        loss = loss_fn(logits, batch[1])\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "        _, predict = logits.max(1)\n",
        "\n",
        "        total_cnt += batch[1].size(0)\n",
        "        correct +=  predict.eq(batch[1]).sum().item()\n",
        "\n",
        "        if step % 100 == 0 and step != 0:\n",
        "            print(f\"\\n====== { step } Step of { len(train_loader) } ======\")\n",
        "            print(f\"Train Acc : { correct / total_cnt }\")\n",
        "            print(f\"Train Loss : { loss.item() / batch[1].size(0) }\")\n",
        "\n",
        "    correct = 0\n",
        "    total_cnt = 0\n",
        "\n",
        "    # Test\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for step, batch in enumerate(test_loader):\n",
        "            # input and target\n",
        "            batch[0], batch[1] = batch[0].to(device), batch[1].to(device)\n",
        "            total_cnt += batch[1].size(0)\n",
        "            logits = model(batch[0])\n",
        "            valid_loss += loss_fn(logits, batch[1])\n",
        "            _, predict = logits.max(1)\n",
        "            correct += predict.eq(batch[1]).sum().item()\n",
        "        valid_acc = correct / total_cnt\n",
        "        print(f\"\\nValid Acc : { valid_acc }\")\n",
        "        print(f\"Valid Loss : { valid_loss / total_cnt }\")\n",
        "\n",
        "        if(valid_acc > best_acc):\n",
        "            best_acc = valid_acc\n",
        "            torch.save(model, model_name)\n",
        "            print(\"Model Saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R8-g_VmTpYGO",
        "outputId": "0f1b3dfe-ea7f-4076-8ea9-d8e167153157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/150 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====== 1 epoch of 150 ======\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.15485767326732675\n",
            "Train Loss : 0.008431224152445793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/150 [01:50<4:34:43, 110.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Valid Acc : 0.2226\n",
            "Valid Loss : 0.00843049120157957\n",
            "Model Saved!\n",
            "====== 2 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.23851330445544555\n",
            "Train Loss : 0.007928382605314255\n",
            "\n",
            "Valid Acc : 0.2789\n",
            "Valid Loss : 0.007953212596476078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 2/150 [03:44<4:38:05, 112.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 3 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.2995049504950495\n",
            "Train Loss : 0.007257702760398388\n",
            "\n",
            "Valid Acc : 0.3567\n",
            "Valid Loss : 0.006878793239593506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 3/150 [05:44<4:43:42, 115.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 4 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.35852413366336633\n",
            "Train Loss : 0.006846493575721979\n",
            "\n",
            "Valid Acc : 0.4222\n",
            "Valid Loss : 0.0062881819903850555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 4/150 [07:44<4:46:11, 117.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 5 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.3961556311881188\n",
            "Train Loss : 0.006119542755186558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 5/150 [09:43<4:45:31, 118.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Valid Acc : 0.39\n",
            "Valid Loss : 0.007040169555693865\n",
            "====== 6 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.43579826732673266\n",
            "Train Loss : 0.005680623464286327\n",
            "\n",
            "Valid Acc : 0.4534\n",
            "Valid Loss : 0.00650556618347764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 6/150 [11:44<4:45:15, 118.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 7 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.46905940594059403\n",
            "Train Loss : 0.005557815078645945\n",
            "\n",
            "Valid Acc : 0.4939\n",
            "Valid Loss : 0.005538885947316885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 7/150 [13:44<4:44:15, 119.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 8 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.4985689975247525\n",
            "Train Loss : 0.00528485095128417\n",
            "\n",
            "Valid Acc : 0.5174\n",
            "Valid Loss : 0.005402952898293734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 8/150 [15:44<4:43:20, 119.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 9 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.5216584158415841\n",
            "Train Loss : 0.0052812485955655575\n",
            "\n",
            "Valid Acc : 0.5387\n",
            "Valid Loss : 0.005211806856095791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 9/150 [17:45<4:42:07, 120.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 10 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.5505105198019802\n",
            "Train Loss : 0.005494485609233379\n",
            "\n",
            "Valid Acc : 0.5431\n",
            "Valid Loss : 0.005167281720787287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 10/150 [19:46<4:40:23, 120.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 11 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.5743734529702971\n",
            "Train Loss : 0.004282016772776842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 11/150 [21:46<4:38:22, 120.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Valid Acc : 0.5174\n",
            "Valid Loss : 0.005740209016948938\n",
            "====== 12 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.6001314975247525\n",
            "Train Loss : 0.004051889758557081\n",
            "\n",
            "Valid Acc : 0.576\n",
            "Valid Loss : 0.0048752436414361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 12/150 [23:46<4:36:32, 120.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 13 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.6243038366336634\n",
            "Train Loss : 0.0036234608851373196\n",
            "\n",
            "Valid Acc : 0.5949\n",
            "Valid Loss : 0.0046732304617762566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 13/150 [25:47<4:35:11, 120.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 14 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.6372215346534653\n",
            "Train Loss : 0.0035028306301683187\n",
            "\n",
            "Valid Acc : 0.6283\n",
            "Valid Loss : 0.00435118842869997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 14/150 [27:48<4:33:19, 120.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 15 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.6532332920792079\n",
            "Train Loss : 0.003292716108262539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 15/150 [29:49<4:31:21, 120.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Valid Acc : 0.6245\n",
            "Valid Loss : 0.0044210124760866165\n",
            "====== 16 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.6687422648514851\n",
            "Train Loss : 0.0038868633564561605\n",
            "\n",
            "Valid Acc : 0.6423\n",
            "Valid Loss : 0.0042333174496889114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 16/150 [31:50<4:29:32, 120.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 17 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.6834003712871287\n",
            "Train Loss : 0.003354523563757539\n",
            "\n",
            "Valid Acc : 0.65\n",
            "Valid Loss : 0.0041038827039301395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 17/150 [33:50<4:27:30, 120.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 18 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.6988319925742574\n",
            "Train Loss : 0.00355724454857409\n",
            "\n",
            "Valid Acc : 0.6771\n",
            "Valid Loss : 0.0037550346460193396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 18/150 [35:51<4:25:49, 120.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 19 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.7166615099009901\n",
            "Train Loss : 0.003138939617201686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 19/150 [37:52<4:23:40, 120.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Valid Acc : 0.6737\n",
            "Valid Loss : 0.003878289368003607\n",
            "====== 20 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.724319306930693\n",
            "Train Loss : 0.0032069210428744555\n",
            "\n",
            "Valid Acc : 0.7164\n",
            "Valid Loss : 0.0033200737088918686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 20/150 [39:52<4:21:20, 120.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 21 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.7443920173267327\n",
            "Train Loss : 0.002944500185549259\n",
            "\n",
            "Valid Acc : 0.7189\n",
            "Valid Loss : 0.003456716425716877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 21/150 [41:53<4:19:32, 120.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 22 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.7583152846534653\n",
            "Train Loss : 0.002741477685049176\n",
            "\n",
            "Valid Acc : 0.7418\n",
            "Valid Loss : 0.0029967024456709623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 22/150 [43:55<4:18:05, 120.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n",
            "====== 23 epoch of 150 ======\n",
            "\n",
            "====== 100 Step of 196 ======\n",
            "Train Acc : 0.7662824876237624\n",
            "Train Loss : 0.002762447576969862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 22/150 [45:35<4:25:14, 124.33s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a36cc20b23aa>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(num_epoch, train_loss, num_epoch, valid_loss)\n",
        "plt.legend(labels=['train', 'valid'], loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9PGFNnJxpq5c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}